#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºè¯Šæ–­æ¨¡å— v2.0 - ç»Ÿä¸€æ¶æ„é‡æ„ç‰ˆ

æ­¤æ¨¡å—æä¾›é¢å¤–çš„è¯Šæ–­åŠŸèƒ½ï¼Œç”¨äºåˆ†æå½±å“è½¨è¿¹è·Ÿè¸ªä½†æœªè¢«æ ‡å‡†è¯Šæ–­è¦†ç›–çš„å‚æ•°ï¼š
1. MPC æƒé‡åˆ†æï¼ˆposition, velocity, heading, control_accel, control_alphaï¼‰
2. ä¸€è‡´æ€§æ£€æŸ¥æ€§èƒ½åˆ†æï¼ˆalpha æ‹’ç»ç‡ï¼Œkappa/v_dir é˜ˆå€¼ï¼‰
3. çŠ¶æ€æœºåˆ‡æ¢åˆ†æï¼ˆåˆ‡æ¢é¢‘ç‡ï¼ŒMPC å¤±è´¥æ£€æµ‹ï¼‰

æ¶æ„æ”¹è¿›ï¼š
- ç»Ÿä¸€ä½¿ç”¨æ¶ˆæ¯ timestampï¼Œä¸å†ä½¿ç”¨ time.time()
- ç»Ÿä¸€å˜åŒ–ç‡è®¡ç®—é€»è¾‘ï¼Œé¿å…é‡å¤
- æ·»åŠ çºµå‘è·Ÿè¸ªè¯¯å·®åˆ†æ
- ä¿®æ­£å•ä½æ ‡æ³¨ï¼ˆm/sÂ² è€Œé m/sÂ²/sï¼‰
- ä¼˜åŒ–å»ºè®®ç”Ÿæˆé€»è¾‘

ä½¿ç”¨æ–¹æ³•:
  # åœ¨ unified_diagnostics.py ä¸­å¯¼å…¥ä½¿ç”¨
  from enhanced_diagnostics import EnhancedDiagnostics
  
  # æˆ–ä½œä¸ºç‹¬ç«‹è„šæœ¬è¿è¡Œ
  rosrun controller_ros enhanced_diagnostics.py --duration 60

ä½œè€…: Kiro Auto-generated
ç‰ˆæœ¬: 2.0
"""

import sys
import os
import numpy as np
import yaml
from collections import deque
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

# ä¿®å¤ Windows ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8')
    os.environ['PYTHONIOENCODING'] = 'utf-8'


@dataclass
class ControlSample:
    """æ§åˆ¶æ ·æœ¬æ•°æ®ç»“æ„"""
    timestamp: float  # æ¶ˆæ¯æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
    vx: float
    vy: float
    omega: float
    lateral_error: float
    longitudinal_error: float  # æ–°å¢ï¼šçºµå‘è¯¯å·®
    heading_error: float
    alpha: float
    state: str
    mpc_success: bool


class EnhancedDiagnostics:
    """
    å¢å¼ºè¯Šæ–­åˆ†æå™¨ v2.0
    
    ç»Ÿä¸€æ¶æ„ï¼Œé¿å…é‡å¤è®¡ç®—ï¼Œæä¾›å®Œæ•´çš„å‚æ•°è¯Šæ–­
    """
    
    def __init__(self, window_size: int = 200):
        """
        åˆå§‹åŒ–
        
        Args:
            window_size: æ»‘åŠ¨çª—å£å¤§å°ï¼ˆé»˜è®¤200ä¸ªæ ·æœ¬ï¼‰
        """
        self.window_size = window_size
        self.samples = deque(maxlen=window_size)
        
        # ç»Ÿè®¡æ•°æ®
        self.state_transitions = []  # (timestamp, from_state, to_state)
        self.alpha_rejections = 0
        self.total_samples = 0
        
    def add_sample(self, diag: Dict[str, Any]):
        """
        æ·»åŠ è¯Šæ–­æ ·æœ¬
        
        Args:
            diag: DiagnosticsV2 æ¶ˆæ¯å­—å…¸ï¼Œå¿…é¡»åŒ…å« timestamp
        """
        # ä½¿ç”¨æ¶ˆæ¯è‡ªå¸¦çš„ timestampï¼Œè€Œä¸æ˜¯ time.time()
        timestamp = diag.get('timestamp', 0.0)
        if timestamp == 0.0:
            # å¦‚æœæ¶ˆæ¯æ²¡æœ‰ timestampï¼Œä½¿ç”¨ header.stamp
            header = diag.get('header')
            if header:
                timestamp = header.stamp.to_sec() if hasattr(header.stamp, 'to_sec') else float(header.stamp.secs) + float(header.stamp.nsecs) * 1e-9
        
        sample = ControlSample(
            timestamp=timestamp,
            vx=diag.get('cmd_vx', 0.0),
            vy=diag.get('cmd_vy', 0.0),
            omega=diag.get('cmd_omega', 0.0),
            lateral_error=diag.get('tracking_lateral_error', 0.0),
            longitudinal_error=diag.get('tracking_longitudinal_error', 0.0),
            heading_error=diag.get('tracking_heading_error', 0.0),
            alpha=diag.get('alpha', 1.0),
            state=diag.get('state', 'UNKNOWN'),
            mpc_success=diag.get('mpc_success', False)
        )
        
        # æ£€æµ‹çŠ¶æ€åˆ‡æ¢
        if len(self.samples) > 0:
            last_state = self.samples[-1].state
            if last_state != sample.state:
                self.state_transitions.append((sample.timestamp, last_state, sample.state))
        
        # ç»Ÿè®¡ alpha æ‹’ç»ï¼ˆalpha < 0.5 è¡¨ç¤ºä¸€è‡´æ€§æ£€æŸ¥æ‹’ç»ï¼‰
        if sample.alpha < 0.5:
            self.alpha_rejections += 1
        
        self.samples.append(sample)
        self.total_samples += 1
    
    def _calculate_control_derivatives(self) -> Dict[str, Any]:
        """
        ç»Ÿä¸€è®¡ç®—æ§åˆ¶è¾“å‡ºçš„å˜åŒ–ç‡ï¼ˆåŠ é€Ÿåº¦å’Œè§’åŠ é€Ÿåº¦ï¼‰
        
        Returns:
            åŒ…å«æ‰€æœ‰å˜åŒ–ç‡æŒ‡æ ‡çš„å­—å…¸
        """
        if len(self.samples) < 2:
            return None
        
        vx_changes = []
        omega_changes = []
        
        for i in range(1, len(self.samples)):
            dt = self.samples[i].timestamp - self.samples[i-1].timestamp
            
            # è¿‡æ»¤å¼‚å¸¸æ—¶é—´é—´éš”
            if dt <= 0 or dt > 0.5:
                continue
            
            # è®¡ç®—å˜åŒ–ç‡ï¼ˆåŠ é€Ÿåº¦ = dv/dtï¼‰
            dvx = abs(self.samples[i].vx - self.samples[i-1].vx) / dt
            domega = abs(self.samples[i].omega - self.samples[i-1].omega) / dt
            
            vx_changes.append(dvx)
            omega_changes.append(domega)
        
        if not vx_changes:
            return None
        
        return {
            'avg_accel': np.mean(vx_changes),
            'max_accel': np.max(vx_changes),
            'avg_angular_accel': np.mean(omega_changes),
            'max_angular_accel': np.max(omega_changes),
            'vx_std': np.std([s.vx for s in self.samples]),
            'omega_std': np.std([s.omega for s in self.samples])
        }
    
    def analyze_mpc_weights(self) -> Dict[str, Any]:
        """
        åˆ†æ MPC æƒé‡æ˜¯å¦åˆç†
        
        æ£€æµ‹ 5 ä¸ªæƒé‡å‚æ•°ï¼šposition, velocity, heading, control_accel, control_alpha
        é€šè¿‡è·Ÿè¸ªè¯¯å·®å’Œæ§åˆ¶å¹³æ»‘æ€§çš„æƒè¡¡æ¥åˆ¤æ–­æƒé‡è®¾ç½®
        
        Returns:
            åˆ†æç»“æœå’Œå»ºè®®
        """
        if len(self.samples) < 10:
            return {"status": "insufficient_data", "message": "éœ€è¦æ›´å¤šæ•°æ®ï¼ˆè‡³å°‘10ä¸ªæ ·æœ¬ï¼‰"}
        
        # è®¡ç®—è·Ÿè¸ªè¯¯å·®
        lateral_errors = [abs(s.lateral_error) for s in self.samples]
        longitudinal_errors = [abs(s.longitudinal_error) for s in self.samples]
        heading_errors = [abs(s.heading_error) for s in self.samples]
        
        avg_lateral = np.mean(lateral_errors)
        max_lateral = np.max(lateral_errors)
        avg_longitudinal = np.mean(longitudinal_errors)
        max_longitudinal = np.max(longitudinal_errors)
        avg_heading = np.mean(heading_errors)
        max_heading = np.max(heading_errors)
        
        # è®¡ç®—æ§åˆ¶å¹³æ»‘æ€§
        derivatives = self._calculate_control_derivatives()
        if not derivatives:
            return {"status": "insufficient_data", "message": "æ— æ³•è®¡ç®—æ§åˆ¶å˜åŒ–ç‡"}
        
        # æ„å»ºç»“æœ
        result = {
            "status": "ok",
            "metrics": {
                "avg_lateral_error": avg_lateral,
                "max_lateral_error": max_lateral,
                "avg_longitudinal_error": avg_longitudinal,
                "max_longitudinal_error": max_longitudinal,
                "avg_heading_error": avg_heading,
                "max_heading_error": max_heading,
                "avg_accel": derivatives['avg_accel'],
                "max_accel": derivatives['max_accel'],
                "avg_angular_accel": derivatives['avg_angular_accel'],
                "max_angular_accel": derivatives['max_angular_accel']
            },
            "suggestions": []
        }
        
        # åˆ¤æ–­é€»è¾‘ï¼šè¯¯å·®å¤§ä½†æ§åˆ¶å¹³æ»‘ â†’ è·Ÿè¸ªæƒé‡è¿‡ä½
        # é˜ˆå€¼è¯´æ˜ï¼š
        # - æ¨ªå‘è¯¯å·® > 0.15m è®¤ä¸ºè¾ƒå¤§
        # - çºµå‘è¯¯å·® > 0.20m è®¤ä¸ºè¾ƒå¤§
        # - èˆªå‘è¯¯å·® > 0.3 rad (17Â°) è®¤ä¸ºè¾ƒå¤§
        # - åŠ é€Ÿåº¦ < 3.0 m/sÂ² è®¤ä¸ºå¹³æ»‘
        # - è§’åŠ é€Ÿåº¦ < 5.0 rad/sÂ² è®¤ä¸ºå¹³æ»‘
        
        if avg_lateral > 0.15 and derivatives['max_accel'] < 3.0:
            result["suggestions"].append({
                "parameter": "mpc.weights.position",
                "current_issue": f"æ¨ªå‘è¯¯å·®è¾ƒå¤§ (avg={avg_lateral:.3f}m, max={max_lateral:.3f}m) ä½†æ§åˆ¶å¾ˆå¹³æ»‘",
                "suggestion": "å¢åŠ  position æƒé‡ (å»ºè®®ä» 10.0 â†’ 15.0)",
                "priority": "high"
            })
        
        if avg_longitudinal > 0.20 and derivatives['max_accel'] < 3.0:
            result["suggestions"].append({
                "parameter": "mpc.weights.velocity",
                "current_issue": f"çºµå‘è¯¯å·®è¾ƒå¤§ (avg={avg_longitudinal:.3f}m, max={max_longitudinal:.3f}m) ä½†æ§åˆ¶å¾ˆå¹³æ»‘",
                "suggestion": "å¢åŠ  velocity æƒé‡ (å»ºè®®ä» 5.0 â†’ 8.0)",
                "priority": "high"
            })
        
        if avg_heading > 0.3 and derivatives['max_angular_accel'] < 5.0:
            result["suggestions"].append({
                "parameter": "mpc.weights.heading",
                "current_issue": f"èˆªå‘è¯¯å·®è¾ƒå¤§ (avg={np.rad2deg(avg_heading):.1f}Â°, max={np.rad2deg(max_heading):.1f}Â°) ä½†æ§åˆ¶å¾ˆå¹³æ»‘",
                "suggestion": "å¢åŠ  heading æƒé‡ (å»ºè®®ä» 5.0 â†’ 8.0)",
                "priority": "high"
            })
        
        # åˆ¤æ–­é€»è¾‘ï¼šæ§åˆ¶æŠ–åŠ¨å¤§ â†’ å¹³æ»‘æƒé‡è¿‡ä½
        # é˜ˆå€¼è¯´æ˜ï¼š
        # - åŠ é€Ÿåº¦ > 8.0 m/sÂ² è®¤ä¸ºæŠ–åŠ¨å¤§
        # - è§’åŠ é€Ÿåº¦ > 15.0 rad/sÂ² è®¤ä¸ºæŠ–åŠ¨å¤§
        
        if derivatives['max_accel'] > 8.0:
            result["suggestions"].append({
                "parameter": "mpc.weights.control_accel",
                "current_issue": f"åŠ é€Ÿåº¦å˜åŒ–è¿‡å¤§ (avg={derivatives['avg_accel']:.2f} m/sÂ², max={derivatives['max_accel']:.2f} m/sÂ²)",
                "suggestion": "å¢åŠ  control_accel æƒé‡ (å»ºè®®ä» 0.2 â†’ 0.5)",
                "priority": "high"
            })
        
        if derivatives['max_angular_accel'] > 15.0:
            result["suggestions"].append({
                "parameter": "mpc.weights.control_alpha",
                "current_issue": f"è§’åŠ é€Ÿåº¦å˜åŒ–è¿‡å¤§ (avg={derivatives['avg_angular_accel']:.2f} rad/sÂ², max={derivatives['max_angular_accel']:.2f} rad/sÂ²)",
                "suggestion": "å¢åŠ  control_alpha æƒé‡ (å»ºè®®ä» 0.2 â†’ 0.5)",
                "priority": "high"
            })
        
        # åˆ¤æ–­é€»è¾‘ï¼šè¯¯å·®å°ä¸”æ§åˆ¶å¹³æ»‘ â†’ æƒé‡è®¾ç½®è‰¯å¥½
        if avg_lateral < 0.10 and avg_longitudinal < 0.15 and derivatives['max_accel'] < 3.0:
            result["suggestions"].append({
                "parameter": "mpc.weights",
                "current_issue": "æ— ",
                "suggestion": "æƒé‡è®¾ç½®è‰¯å¥½ï¼Œè·Ÿè¸ªç²¾åº¦å’Œå¹³æ»‘æ€§å¹³è¡¡",
                "priority": "info"
            })
        
        return result
    
    def analyze_consistency_check(self) -> Dict[str, Any]:
        """
        åˆ†æä¸€è‡´æ€§æ£€æŸ¥æ€§èƒ½
        
        æ£€æµ‹å‚æ•°ï¼škappa_thresh, v_dir_thresh
        é€šè¿‡ alpha æ‹’ç»ç‡åˆ¤æ–­é˜ˆå€¼æ˜¯å¦è¿‡ä¸¥
        
        Returns:
            åˆ†æç»“æœå’Œå»ºè®®
        """
        if self.total_samples < 10:
            return {"status": "insufficient_data", "message": "éœ€è¦æ›´å¤šæ•°æ®ï¼ˆè‡³å°‘10ä¸ªæ ·æœ¬ï¼‰"}
        
        rejection_rate = self.alpha_rejections / self.total_samples
        
        # ç»Ÿè®¡ alpha åˆ†å¸ƒ
        alpha_values = [s.alpha for s in self.samples]
        avg_alpha = np.mean(alpha_values)
        min_alpha = np.min(alpha_values)
        
        result = {
            "status": "ok",
            "metrics": {
                "rejection_rate": rejection_rate,
                "rejection_count": self.alpha_rejections,
                "total_samples": self.total_samples,
                "avg_alpha": avg_alpha,
                "min_alpha": min_alpha
            },
            "suggestions": []
        }
        
        # åˆ¤æ–­é€»è¾‘ï¼šæ‹’ç»ç‡è¿‡é«˜ â†’ é˜ˆå€¼è¿‡ä¸¥
        # é˜ˆå€¼è¯´æ˜ï¼š
        # - æ‹’ç»ç‡ > 10% è®¤ä¸ºè¿‡é«˜
        # - æ‹’ç»ç‡ 5-10% è®¤ä¸ºåé«˜
        # - æ‹’ç»ç‡ < 5% è®¤ä¸ºè‰¯å¥½
        
        if rejection_rate > 0.1:
            result["suggestions"].append({
                "parameter": "consistency.kappa_thresh / v_dir_thresh",
                "current_issue": f"ä¸€è‡´æ€§æ£€æŸ¥æ‹’ç»ç‡è¿‡é«˜ ({rejection_rate*100:.1f}%)",
                "suggestion": "æ”¾å®½ä¸€è‡´æ€§é˜ˆå€¼ (kappa_thresh: 0.5â†’0.7, v_dir_thresh: 0.8â†’0.9)",
                "priority": "high"
            })
        elif rejection_rate > 0.05:
            result["suggestions"].append({
                "parameter": "consistency.kappa_thresh / v_dir_thresh",
                "current_issue": f"ä¸€è‡´æ€§æ£€æŸ¥æ‹’ç»ç‡åé«˜ ({rejection_rate*100:.1f}%)",
                "suggestion": "è€ƒè™‘é€‚å½“æ”¾å®½é˜ˆå€¼ (kappa_thresh: +0.1, v_dir_thresh: +0.05)",
                "priority": "medium"
            })
        else:
            result["suggestions"].append({
                "parameter": "consistency check",
                "current_issue": "æ— ",
                "suggestion": f"ä¸€è‡´æ€§æ£€æŸ¥æ€§èƒ½è‰¯å¥½ (æ‹’ç»ç‡ {rejection_rate*100:.1f}%)",
                "priority": "info"
            })
        
        # åˆ¤æ–­é€»è¾‘ï¼šmin_alpha å¾ˆä½ â†’ è½¨è¿¹è´¨é‡é—®é¢˜
        # é˜ˆå€¼è¯´æ˜ï¼š
        # - min_alpha < 0.2 è®¤ä¸ºä¸¥é‡é—®é¢˜
        # - min_alpha < 0.3 è®¤ä¸ºéœ€è¦å…³æ³¨
        
        if min_alpha < 0.2:
            result["suggestions"].append({
                "parameter": "trajectory quality",
                "current_issue": f"æ£€æµ‹åˆ°ä¸¥é‡çš„è½¨è¿¹ä¸€è‡´æ€§é—®é¢˜ (min_alpha={min_alpha:.2f})",
                "suggestion": "æ£€æŸ¥è½¨è¿¹å‘å¸ƒèŠ‚ç‚¹ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®è´¨é‡é—®é¢˜æˆ–ç½‘ç»œå»¶è¿Ÿ",
                "priority": "critical"
            })
        elif min_alpha < 0.3:
            result["suggestions"].append({
                "parameter": "trajectory quality",
                "current_issue": f"æ£€æµ‹åˆ°è½¨è¿¹ä¸€è‡´æ€§åä½ (min_alpha={min_alpha:.2f})",
                "suggestion": "å»ºè®®æ£€æŸ¥è½¨è¿¹å‘å¸ƒé¢‘ç‡å’Œè´¨é‡",
                "priority": "medium"
            })
        
        return result
    
    def analyze_state_machine(self) -> Dict[str, Any]:
        """
        åˆ†æçŠ¶æ€æœºåˆ‡æ¢é¢‘ç‡
        
        æ£€æµ‹å‚æ•°ï¼šmpc_fail_thresh, mpc_recovery_thresh
        é€šè¿‡åˆ‡æ¢é¢‘ç‡å’Œç±»å‹åˆ¤æ–­çŠ¶æ€æœºå‚æ•°æ˜¯å¦åˆç†
        
        Returns:
            åˆ†æç»“æœå’Œå»ºè®®
        """
        if len(self.state_transitions) == 0:
            return {
                "status": "ok",
                "metrics": {
                    "transition_count": 0,
                    "transition_rate": 0.0,
                    "transition_types": {}
                },
                "suggestions": [{
                    "parameter": "state machine",
                    "current_issue": "æ— ",
                    "suggestion": "æ— çŠ¶æ€åˆ‡æ¢ï¼Œæ§åˆ¶å™¨ç¨³å®šè¿è¡Œ",
                    "priority": "info"
                }]
            }
        
        # ç»Ÿè®¡åˆ‡æ¢é¢‘ç‡
        if len(self.samples) > 1:
            duration = self.samples[-1].timestamp - self.samples[0].timestamp
            transition_rate = len(self.state_transitions) / max(duration, 1.0)
        else:
            transition_rate = 0.0
        
        # ç»Ÿè®¡åˆ‡æ¢ç±»å‹
        transition_types = {}
        mpc_to_backup_count = 0
        backup_to_mpc_count = 0
        
        for _, from_state, to_state in self.state_transitions:
            key = f"{from_state} â†’ {to_state}"
            transition_types[key] = transition_types.get(key, 0) + 1
            
            # ç»Ÿè®¡ MPC å¤±è´¥åˆ‡æ¢
            if "MPC" in from_state and "BACKUP" in to_state:
                mpc_to_backup_count += 1
            elif "BACKUP" in from_state and "MPC" in to_state:
                backup_to_mpc_count += 1
        
        result = {
            "status": "ok",
            "metrics": {
                "transition_count": len(self.state_transitions),
                "transition_rate": transition_rate,
                "transition_types": transition_types,
                "mpc_to_backup_count": mpc_to_backup_count,
                "backup_to_mpc_count": backup_to_mpc_count
            },
            "suggestions": []
        }
        
        # åˆ¤æ–­é€»è¾‘ï¼šåˆ‡æ¢é¢‘ç¹ â†’ çŠ¶æ€æœºå‚æ•°ä¸å½“
        # é˜ˆå€¼è¯´æ˜ï¼š
        # - åˆ‡æ¢é¢‘ç‡ > 0.5 æ¬¡/ç§’ è®¤ä¸ºé¢‘ç¹
        # - åˆ‡æ¢é¢‘ç‡ > 0.1 æ¬¡/ç§’ è®¤ä¸ºåé«˜
        
        if transition_rate > 0.5:
            result["suggestions"].append({
                "parameter": "safety.state_machine.mpc_fail_thresh / mpc_recovery_thresh",
                "current_issue": f"çŠ¶æ€åˆ‡æ¢é¢‘ç¹ ({transition_rate:.2f} æ¬¡/ç§’)",
                "suggestion": "è°ƒæ•´çŠ¶æ€æœºå‚æ•°ï¼Œå‡å°‘ä¸å¿…è¦çš„åˆ‡æ¢ (mpc_fail_thresh: 3â†’5, mpc_recovery_thresh: 5â†’3)",
                "priority": "high"
            })
        elif transition_rate > 0.1:
            result["suggestions"].append({
                "parameter": "safety.state_machine",
                "current_issue": f"çŠ¶æ€åˆ‡æ¢åé¢‘ç¹ ({transition_rate:.2f} æ¬¡/ç§’)",
                "suggestion": "è€ƒè™‘è°ƒæ•´çŠ¶æ€æœºå‚æ•°",
                "priority": "medium"
            })
        
        # åˆ¤æ–­é€»è¾‘ï¼šMPC å¤±è´¥åˆ‡æ¢ â†’ MPC æ€§èƒ½æˆ–å¤‡ç”¨æ§åˆ¶å™¨é—®é¢˜
        if mpc_to_backup_count > 0:
            result["suggestions"].append({
                "parameter": "MPC performance / backup controller",
                "current_issue": f"æ£€æµ‹åˆ° {mpc_to_backup_count} æ¬¡ MPC å¤±è´¥åˆ‡æ¢åˆ°å¤‡ç”¨æ§åˆ¶å™¨",
                "suggestion": "æ£€æŸ¥ MPC æ±‚è§£å™¨å¥åº·åº¦ï¼Œæˆ–ä¼˜åŒ–å¤‡ç”¨æ§åˆ¶å™¨å‚æ•°",
                "priority": "high" if mpc_to_backup_count > 5 else "medium"
            })
        
        return result
    
    def generate_report(self) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„å¢å¼ºè¯Šæ–­æŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„æŠ¥å‘Šæ–‡æœ¬
        """
        report = []
        report.append("\n" + "="*70)
        report.append("  å¢å¼ºè¯Šæ–­æŠ¥å‘Š (Enhanced Diagnostics Report v2.0)")
        report.append("="*70)
        
        # 1. MPC æƒé‡åˆ†æ
        report.append("\nã€1. MPC æƒé‡åˆ†æã€‘")
        mpc_result = self.analyze_mpc_weights()
        if mpc_result["status"] == "ok":
            m = mpc_result["metrics"]
            report.append(f"  æ¨ªå‘è¯¯å·®: avg={m['avg_lateral_error']:.3f}m, max={m['max_lateral_error']:.3f}m")
            report.append(f"  çºµå‘è¯¯å·®: avg={m['avg_longitudinal_error']:.3f}m, max={m['max_longitudinal_error']:.3f}m")
            report.append(f"  èˆªå‘è¯¯å·®: avg={np.rad2deg(m['avg_heading_error']):.1f}Â°, max={np.rad2deg(m['max_heading_error']):.1f}Â°")
            report.append(f"  åŠ é€Ÿåº¦: avg={m['avg_accel']:.2f} m/sÂ², max={m['max_accel']:.2f} m/sÂ²")
            report.append(f"  è§’åŠ é€Ÿåº¦: avg={m['avg_angular_accel']:.2f} rad/sÂ², max={m['max_angular_accel']:.2f} rad/sÂ²")
            
            if mpc_result["suggestions"]:
                report.append("\n  å»ºè®®:")
                for sug in mpc_result["suggestions"]:
                    icon = {"critical": "ğŸ”´", "high": "âš ï¸", "medium": "â„¹ï¸", "info": "âœ…"}.get(sug["priority"], "â€¢")
                    report.append(f"    {icon} {sug['parameter']}")
                    report.append(f"       é—®é¢˜: {sug['current_issue']}")
                    report.append(f"       å»ºè®®: {sug['suggestion']}")
        else:
            report.append(f"  {mpc_result['message']}")
        
        # 2. ä¸€è‡´æ€§æ£€æŸ¥åˆ†æ
        report.append("\nã€2. ä¸€è‡´æ€§æ£€æŸ¥åˆ†æã€‘")
        consistency_result = self.analyze_consistency_check()
        if consistency_result["status"] == "ok":
            m = consistency_result["metrics"]
            report.append(f"  æ‹’ç»ç‡: {m['rejection_rate']*100:.1f}% ({m['rejection_count']}/{m['total_samples']})")
            report.append(f"  Alpha: avg={m['avg_alpha']:.3f}, min={m['min_alpha']:.3f}")
            
            if consistency_result["suggestions"]:
                report.append("\n  å»ºè®®:")
                for sug in consistency_result["suggestions"]:
                    icon = {"critical": "ğŸ”´", "high": "âš ï¸", "medium": "â„¹ï¸", "info": "âœ…"}.get(sug["priority"], "â€¢")
                    report.append(f"    {icon} {sug['parameter']}")
                    report.append(f"       é—®é¢˜: {sug['current_issue']}")
                    report.append(f"       å»ºè®®: {sug['suggestion']}")
        else:
            report.append(f"  {consistency_result['message']}")
        
        # 3. çŠ¶æ€æœºåˆ‡æ¢åˆ†æ
        report.append("\nã€3. çŠ¶æ€æœºåˆ‡æ¢åˆ†æã€‘")
        state_result = self.analyze_state_machine()
        m = state_result["metrics"]
        report.append(f"  åˆ‡æ¢æ¬¡æ•°: {m['transition_count']}")
        if m['transition_count'] > 0:
            report.append(f"  åˆ‡æ¢é¢‘ç‡: {m['transition_rate']:.2f} æ¬¡/ç§’")
            report.append(f"  MPCâ†’Backup: {m['mpc_to_backup_count']} æ¬¡")
            report.append(f"  Backupâ†’MPC: {m['backup_to_mpc_count']} æ¬¡")
            report.append("  åˆ‡æ¢ç±»å‹:")
            for trans_type, count in m['transition_types'].items():
                report.append(f"    {trans_type}: {count} æ¬¡")
        
        if state_result["suggestions"]:
            report.append("\n  å»ºè®®:")
            for sug in state_result["suggestions"]:
                icon = {"critical": "ğŸ”´", "high": "âš ï¸", "medium": "â„¹ï¸", "info": "âœ…"}.get(sug["priority"], "â€¢")
                report.append(f"    {icon} {sug['parameter']}")
                report.append(f"       é—®é¢˜: {sug['current_issue']}")
                report.append(f"       å»ºè®®: {sug['suggestion']}")
        
        report.append("\n" + "="*70)
        
        return "\n".join(report)
    
    def get_all_suggestions(self) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰å»ºè®®ï¼ˆç”¨äºé…ç½®æ–‡ä»¶ç”Ÿæˆï¼‰
        
        Returns:
            æŒ‰ä¼˜å…ˆçº§æ’åºçš„å»ºè®®åˆ—è¡¨
        """
        all_suggestions = []
        
        # æ”¶é›†æ‰€æœ‰åˆ†æçš„å»ºè®®
        for analysis_func in [
            self.analyze_mpc_weights,
            self.analyze_consistency_check,
            self.analyze_state_machine
        ]:
            result = analysis_func()
            if result.get("status") == "ok" and "suggestions" in result:
                all_suggestions.extend(result["suggestions"])
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"critical": 0, "high": 1, "medium": 2, "info": 3}
        all_suggestions.sort(key=lambda x: priority_order.get(x["priority"], 99))
        
        return all_suggestions


# ç‹¬ç«‹è¿è¡Œæ—¶çš„ä¸»å‡½æ•°
if __name__ == '__main__':
    try:
        import rospy
        from controller_ros.msg import DiagnosticsV2
    except ImportError:
        print("é”™è¯¯: æ— æ³•å¯¼å…¥ ROS æˆ– controller_ros æ¶ˆæ¯")
        print("è¯·ç¡®ä¿åœ¨ ROS ç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    
    import argparse
    
    parser = argparse.ArgumentParser(description='å¢å¼ºè¯Šæ–­å·¥å…· - ç‹¬ç«‹è¿è¡Œæ¨¡å¼')
    parser.add_argument('--duration', type=float, default=60.0, help='è¯Šæ–­æŒç»­æ—¶é—´(ç§’)')
    parser.add_argument('--output', type=str, default='enhanced_diagnostics_suggestions.yaml', 
                        help='å»ºè®®è¾“å‡ºæ–‡ä»¶')
    args = parser.parse_args()
    
    print("="*70)
    print("  å¢å¼ºè¯Šæ–­å·¥å…· v2.0 - ç‹¬ç«‹è¿è¡Œæ¨¡å¼")
    print("="*70)
    print(f"\nè®¢é˜… /controller/diagnostics è¿›è¡Œåˆ†æ...")
    print(f"æŒç»­æ—¶é—´: {args.duration} ç§’\n")
    
    rospy.init_node('enhanced_diagnostics', anonymous=True)
    
    analyzer = EnhancedDiagnostics(window_size=200)
    
    def diagnostics_callback(msg):
        """è¯Šæ–­æ¶ˆæ¯å›è°ƒ"""
        diag_dict = {
            'header': msg.header,
            'cmd_vx': msg.cmd_vx,
            'cmd_vy': msg.cmd_vy,
            'cmd_omega': msg.cmd_omega,
            'tracking_lateral_error': msg.tracking_lateral_error,
            'tracking_longitudinal_error': msg.tracking_longitudinal_error,
            'tracking_heading_error': msg.tracking_heading_error,
            'alpha': msg.consistency_alpha_soft,  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
            'state': msg.state,
            'mpc_success': msg.mpc_success
        }
        analyzer.add_sample(diag_dict)
    
    sub = rospy.Subscriber('/controller/diagnostics', DiagnosticsV2, diagnostics_callback)
    
    print(f"æ”¶é›†æ•°æ® {args.duration} ç§’...")
    rospy.sleep(args.duration)
    
    # ç”ŸæˆæŠ¥å‘Š
    print(analyzer.generate_report())
    
    # ä¿å­˜å»ºè®®åˆ°æ–‡ä»¶
    suggestions = analyzer.get_all_suggestions()
    if suggestions:
        print(f"\nä¿å­˜å»ºè®®åˆ° {args.output}...")
        with open(args.output, 'w', encoding='utf-8') as f:
            yaml.dump({'suggestions': suggestions}, f, default_flow_style=False, allow_unicode=True)
        print("å®Œæˆ!")
    else:
        print("\næ— å»ºè®®éœ€è¦ä¿å­˜")
